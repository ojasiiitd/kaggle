{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Conv2D , MaxPooling2D , Dropout , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator , load_img , img_to_array\n",
    "from keras.preprocessing import image\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgWidth = 200\n",
    "imgHeight = 200\n",
    "stride = (2,2)\n",
    "pool = (2,2)\n",
    "batch = 32\n",
    "epochs = 15\n",
    "\n",
    "if backend.image_data_format() == \"channels_first\":\n",
    "    input_shape = (3 , imgWidth , imgHeight)\n",
    "else:\n",
    "    input_shape = (imgWidth , imgHeight , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = train_datagen.flow_from_directory(\n",
    "    \"train/\",\n",
    "    target_size=(imgWidth , imgHeight),\n",
    "    batch_size=batch,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = test_datagen.flow_from_directory(\n",
    "    \"val/\",\n",
    "    target_size=(imgWidth , imgHeight),\n",
    "    batch_size=batch,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 200, 200, 32)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 100, 100, 128)     16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 1600005   \n",
      "=================================================================\n",
      "Total params: 1,616,933\n",
      "Trainable params: 1,616,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add( Conv2D(32 , stride , padding=\"same\" , activation=\"relu\" , input_shape=input_shape) )\n",
    "model.add( MaxPooling2D(pool) )\n",
    "\n",
    "model.add( Dropout(0.3) )\n",
    "\n",
    "model.add( Conv2D(128, stride , padding=\"same\" , activation=\"relu\") )\n",
    "model.add( MaxPooling2D(pool) )\n",
    "\n",
    "model.add( Dropout(0.5) )\n",
    "\n",
    "model.add( Flatten() )\n",
    "\n",
    "model.add( Dense(5 , activation=\"softmax\") )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\" , loss=\"categorical_crossentropy\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 3s 847ms/step - loss: 4.6812 - accuracy: 0.2473 - val_loss: 4.3367 - val_accuracy: 0.2000\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 2s 730ms/step - loss: 6.8885 - accuracy: 0.2366 - val_loss: 2.1984 - val_accuracy: 0.2000\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 2s 785ms/step - loss: 3.2215 - accuracy: 0.3226 - val_loss: 1.6878 - val_accuracy: 0.2800\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 2s 795ms/step - loss: 1.9451 - accuracy: 0.3656 - val_loss: 1.6055 - val_accuracy: 0.4000\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 2s 829ms/step - loss: 1.4737 - accuracy: 0.4194 - val_loss: 1.6394 - val_accuracy: 0.2000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 2s 817ms/step - loss: 1.4289 - accuracy: 0.3441 - val_loss: 1.5972 - val_accuracy: 0.2000\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 2s 768ms/step - loss: 1.3122 - accuracy: 0.4946 - val_loss: 1.5436 - val_accuracy: 0.2800\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.2687 - accuracy: 0.5161 - val_loss: 1.5315 - val_accuracy: 0.3600\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 2s 783ms/step - loss: 1.2155 - accuracy: 0.5484 - val_loss: 1.5192 - val_accuracy: 0.3600\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 2s 742ms/step - loss: 1.1227 - accuracy: 0.6237 - val_loss: 1.5194 - val_accuracy: 0.3600\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 2s 760ms/step - loss: 1.0305 - accuracy: 0.6774 - val_loss: 1.4849 - val_accuracy: 0.4000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 2s 793ms/step - loss: 0.9315 - accuracy: 0.6989 - val_loss: 1.4320 - val_accuracy: 0.4000\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 2s 756ms/step - loss: 0.8450 - accuracy: 0.7312 - val_loss: 1.3727 - val_accuracy: 0.4000\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 2s 752ms/step - loss: 0.7339 - accuracy: 0.7849 - val_loss: 1.2947 - val_accuracy: 0.4000\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 2s 795ms/step - loss: 0.6869 - accuracy: 0.8065 - val_loss: 1.2609 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d932e3cf8>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = load_img(\"EJ.jpg\" , target_size=(imgWidth , imgHeight))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ben_afflek': 0,\n",
       " 'elton_john': 1,\n",
       " 'jerry_seinfeld': 2,\n",
       " 'madonna': 3,\n",
       " 'mindy_kaling': 4}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_classes(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
